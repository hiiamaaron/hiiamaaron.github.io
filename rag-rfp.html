<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>RFP RAG â€” Stacked Retrievers | Aaron (ë°°ë™ìš°)</title>
  <style>
    :root {
      --bg-dark: #0f172a;
      --bg-alt1: #111827;
      --bg-alt2: linear-gradient(180deg, #0f172a 0%, #1e293b 100%);
      --card-dark: #1f2937;
      --text-light: #f3f4f6;
      --accent-blue: #3b82f6;
      --muted: #9ca3af;
      --shadow-dark: 0 2px 10px rgba(0,0,0,0.4);
      --hover-glow: 0 0 12px rgba(59,130,246,0.22);
      --radius-lg: 1.5rem;
      --radius-md: 1.0rem;
      --max-width: 1000px;
    }

    * { box-sizing: border-box; scroll-behavior: smooth; }
    body {
      font-family: "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      background-color: var(--bg-dark);
      color: var(--text-light);
      margin: 0;
      line-height: 1.6;
      -webkit-font-smoothing:antialiased;
    }

    nav {
      position: fixed;
      top: 0;
      width: 100%;
      background-color: rgba(15, 23, 42, 0.92);
      backdrop-filter: blur(6px);
      display: flex;
      justify-content: center;
      gap: 2rem;
      padding: 0.9rem 0.6rem;
      z-index: 1000;
      border-bottom: 1px solid rgba(59,130,246,0.12);
    }
    nav a { color: var(--text-light); text-decoration: none; font-weight: 500; transition: color .25s; }
    nav a:hover { color: var(--accent-blue); }

    header {
      background: linear-gradient(90deg,#2563eb,#0891b2);
      color: white;
      text-align: center;
      padding: 6.2rem 1rem 1.6rem;
      display: flex;
      flex-direction: column;
      align-items: center;
      gap: 0.6rem;
    }

    .profile-photo {
      width: 92px;
      height: 92px;
      border-radius: 50%;
      object-fit: cover;
      border: 3px solid rgba(255,255,255,0.9);
      box-shadow: 0 6px 20px rgba(0,0,0,0.35);
    }

    header h1 { font-size: 1.6rem; margin: 0; }
    header p { margin: 0; color: #e0f2fe; font-size: 0.98rem; }

    main {
      max-width: var(--max-width);
      margin: 2rem auto;
      padding: 1.2rem;
    }

    .project-shell {
      background: var(--bg-alt1);
      border-radius: var(--radius-lg);
      padding: 1.6rem;
      box-shadow: inset 0 0 40px rgba(0,0,0,0.25);
    }

    h2 {
      margin-top: 0;
      color: #93c5fd;
      padding-bottom: 0.35rem;
      border-bottom: 2px solid rgba(55,65,81,0.7);
      text-shadow: 0 0 6px rgba(147,197,253,0.35);
    }

    section { margin: 1.25rem 0; }
    p { color: #e5e7eb; margin: 0.6rem 0; }
    .dual { color: #a1a1aa; font-size: 0.95em; display:block; margin-top:0.4rem; }

    .metric-table {
      width: 100%;
      border-collapse: collapse;
      margin-top: 0.9rem;
      margin-bottom: 1rem;
    }
    .metric-table th, .metric-table td {
      border: 1px solid #334155;
      padding: 0.6rem;
      text-align: center;
    }
    .metric-table th { background: #1e293b; color: #93c5fd; }

    pre.code {
      background: #0b1220;
      border: 1px solid #334155;
      color: #dbeafe;
      padding: 1rem;
      border-radius: 8px;
      overflow: auto;
      font-family: Consolas, "Courier New", monospace;
      font-size: 0.92em;
    }

    figure { text-align: center; margin: 1rem 0; }
    figure img {
      width: 100%;
      max-height: 460px;
      object-fit: contain;
      border-radius: var(--radius-md);
      box-shadow: 0 12px 30px rgba(0,0,0,0.45);
    }
    figcaption { margin-top: 0.6rem; color: var(--muted); font-size: 0.95rem; }

    .back-link { display:block; text-align:center; margin-top:1.6rem; color:#93c5fd; text-decoration:none; }
    .back-link:hover { text-decoration: underline; }

    .footer {
      text-align: center;
      padding: 1.6rem;
      font-size: 0.9rem;
      color: var(--muted);
      background-color: #0d162b;
      border-top-left-radius: 1.2rem;
      border-top-right-radius: 1.2rem;
      margin-top: 2rem;
    }

    @media (max-width:800px) {
      :root { --max-width: 92%; }
      header { padding-top: 5.8rem; }
      .profile-photo { width:76px; height:76px; }
    }

    code {
      background-color: #0b1220;
      color: #fb923c;
      padding: 2px 6px;
      border-radius: 6px;
      font-family: Consolas, "Courier New", monospace;
      font-size: 0.9em;
    }

    ul { margin: 0.8rem 0 0.8rem 1.2rem; }
    li { margin-bottom: 0.45rem; }
    .note { color: var(--muted); font-size: 0.9rem; font-style: italic; }

  </style>
</head>
<body>
  <nav>
    <a href="index.html#about">About</a>
    <a href="index.html#projects">Projects</a>
    <a href="index.html#contact">Contact</a>
  </nav>

  <header>
    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Mona_Lisa%2C_by_Leonardo_da_Vinci%2C_from_C2RMF_retouched.jpg/800px-Mona_Lisa%2C_by_Leonardo_da_Vinci%2C_from_C2RMF_retouched.jpg" alt="Profile photo" class="profile-photo" />
    <h1>Request for Proposal â€” Stacked Retrievers (RAG)</h1>
    <p>100ë¶€ í•œêµ­ì–´ ì œì•ˆìš”ì²­ì„œ ë¬¸ì„œ ê¸°ë°˜ì˜ Retrieval-Augmented Generation ì‹¤í—˜</p>
  </header>

  <main>
    <div class="project-shell">
      <section aria-labelledby="overview">
        <h2 id="overview">ğŸ“˜ Overview</h2>
        <p>
          Built and evaluated a Retrieval-Augmented Generation (RAG) system for 100 Korean Request For Proposal (RFP) documents.
          Focus: parser comparison (Unstructured IO, MuPDF, pdfplumber), embedding model comparison (SNUNLP S-BERT vs OpenAI text-embedding-ada-002),
          and stacked retriever experiments with FAISS.
          <span class="dual">100ë¶€ì˜ í•œêµ­ì–´ ì œì•ˆìš”ì²­ì„œë¥¼ ëŒ€ìƒìœ¼ë¡œ RAG ì‹œìŠ¤í…œì„ êµ¬í˜„Â·í‰ê°€í–ˆìŠµë‹ˆë‹¤. íŒŒì„œ, ì„ë² ë”©, ìŠ¤íƒí˜• ê²€ìƒ‰ê¸° ë¹„êµê°€ ì£¼ìš” í¬ì¸íŠ¸ì…ë‹ˆë‹¤.</span>
        </p>
      </section>

      <section aria-labelledby="role">
        <h2 id="role">ğŸ‘¥ Role & Preprocessing</h2>
        <p>
          Developed preprocessing tooling and led parser/embedding experiments: converted 98 HWP â†’ PDF (Python), handled conversion anomalies (42 files required manual fixes), and normalized chunking for embedding.
          <span class="dual">ì „ì²˜ë¦¬ ë„êµ¬ë¥¼ ê°œë°œí•˜ê³  íŒŒì„œ/ì„ë² ë”© ì‹¤í—˜ì„ ì£¼ë„í–ˆìŠµë‹ˆë‹¤. 98ë¶€ì˜ HWP íŒŒì¼ì„ ìë™ìœ¼ë¡œ PDFë¡œ ë³€í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í–ˆê³ ,
          ë³€í™˜ ì¤‘ 42ë¶€ ë¬¸ì„œì—ì„œ 'í•œ í˜ì´ì§€ì— ë‘ í˜ì´ì§€ê°€ ë³‘í•©'ë˜ëŠ” ì˜¤ë¥˜ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ë³´ì •í•´ ì •ìƒ íŒŒì‹±ì„ í™•ë³´í–ˆìŠµë‹ˆë‹¤.</span>
        </p>
      </section>

      <section aria-labelledby="parser">
        <h2 id="parser">ğŸ§­ Parser comparison (Unstructured IO / MuPDF / pdfplumber)</h2>
        <p>
          Compared three parsing approaches. Unstructured IO sometimes flattened table semantics, so MuPDF + pdfplumber was adopted for more reliable structure extraction.
          <span class="dual">ì„¸ ê°€ì§€ íŒŒì„œë¥¼ ë¹„êµí•œ ê²°ê³¼, Unstructured IOëŠ” í‘œ/ë„í‘œì˜ í–‰Â·ì—´ êµ¬ì¡° ì •ë³´ê°€ ì œëŒ€ë¡œ ë³´ì¡´ë˜ì§€ ì•ŠëŠ” ê²½ìš°ê°€ ìˆì–´ ìµœì¢…ì ìœ¼ë¡œ MuPDFì™€ pdfplumber ì¡°í•©ì„ ì±„íƒí–ˆìŠµë‹ˆë‹¤.</span>
        </p>
        <p class="note">(Practical note: Unstructured IO can be strong for some layouts but may lose table row/column structure â€” see project report.)</p>
        <span class="dual">(ì‹¤ë¬´ ë…¸íŠ¸: Unstructured IOëŠ” íŠ¹ì • ë ˆì´ì•„ì›ƒ ì²˜ë¦¬ì— ê°•ì ì´ ìˆìœ¼ë‚˜ í‘œì˜ ì˜ë¯¸ì  êµ¬ì¡°ê°€ í‰íƒ„í™”ë˜ëŠ” ì‚¬ë¡€ê°€ ìˆì–´ ë³´ê³ ì„œì— ì¼€ì´ìŠ¤ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.)</span>
      </section>

      <section aria-labelledby="embeddings">
        <h2 id="embeddings">ğŸ§© Embedding experiments (S-BERT vs OpenAI)</h2>
        <p>
          Two embedding pipelines compared:
          <ul>
            <li><strong>SNUNLP S-BERT</strong> (snunlp/KR-SBERT-V40K-klueNLI-augSTS) â†’ ChromaDB</li>
            <li><strong>OpenAI</strong> text-embedding-ada-002 â†’ ChromaDB</li>
          </ul>
          For each pipeline we plotted normalized vector length histograms and t-SNE on original embeddings to inspect distributional properties.
          <span class="dual">(1) ì„œìš¸ëŒ€í•™êµ S-BERT, (2) OpenAI text-embedding-ada-002ë¥¼ ê°ê° Chromaì— ì €ì¥í•˜ê³ , ì •ê·œí™”í•œ ë²¡í„° ê¸¸ì´ íˆìŠ¤í† ê·¸ë¨ê³¼ ì •ê·œí™”í•˜ì§€ ì•Šì€ ì„ë² ë”©ì˜ t-SNEë¥¼ ë¹„êµÂ·ì‹œê°í™”í–ˆìŠµë‹ˆë‹¤.</span>
        </p>

        <figure>
          <img src="rag-rfp-parser.png" alt="Embedding vector length histogram placeholder">
          <figcaption>
            Normalized vector length histogram and t-SNE plot for each parser: Unstructured (left), MuPDF (middle), pdfplumber (right).
            <span class="dual">
              ì‹¤ì œ ì´ë¯¸ì§€ëŠ” ê° íŒŒì„œ(Unstructured, MuPDF, pdfplumber) ë° ì„ë² ë”© ëª¨ë¸ë³„ë¡œ ìƒì„±ëœ ì •ê·œí™”ëœ ë²¡í„° ê¸¸ì´ íˆìŠ¤í† ê·¸ë¨Â·t-SNE í”Œë¡¯ì„ í¬í•¨í•©ë‹ˆë‹¤.
            </span>
          </figcaption>
        </figure>

        <figure>
          <img src="rag-rfp-sbert.png" alt="t-SNE embedding placeholder">
          <figcaption>
            Histogram of normalized vector length (left), non-normalized vector length (middle), and t-SNE of non-normalized embeddings (right) â€” used to inspect semantic cluster structure.
            <span class="dual">
              ì •ê·œí™”ëœ ë²¡í„° ê¸¸ì´ íˆìŠ¤í† ê·¸ë¨(ì¢Œ), ë¹„ì •ê·œí™”ëœ ë²¡í„° ê¸¸ì´ íˆìŠ¤í† ê·¸ë¨(ì¤‘), ë¹„ì •ê·œí™”ëœ ì„ë² ë”©ì˜ t-SNE ê·¸ë˜í”„(ìš°).
            </span>
          </figcaption>
        </figure>
      </section>

      <section aria-labelledby="evaluation">
        <h2 id="evaluation">â“ 22-Question Evaluation (Qualitative)</h2>
        <p>
          We prepared 22 domain-specific queries (example list below) and evaluated responses across three parser data-sets (Original / Plumber / MUP) using OpenAI's text-embedding-ada-002 retrieval pipeline. Responses were manually scored: <strong>+2 (richer), +1 (correct), -1 (incorrect or partially wrong)</strong>.
        <span class="dual">
          22ê°œì˜ ë„ë©”ì¸ ì§ˆë¬¸(ì•„ë˜ ì˜ˆì‹œ)ì„ ë§Œë“¤ì–´ 3ê°œ íŒŒì„œ ë°ì´í„°ì…‹(ê¸°ì¡´ / Plumber / MUP)ì—ì„œì˜ ì‘ë‹µì„ OpenAI ì„ë² ë”© ê¸°ë°˜ RAGë¡œ ì–»ì–´ ìˆ˜ë™ í‰ê°€í–ˆìŠµë‹ˆë‹¤. í‰ê°€ëŠ” <strong>+2(ì •ë³´ê°€ ë” í’ë¶€í•¨), +1(ì •í™•í•¨), -1(ì˜¤ë¥˜ í¬í•¨)</strong> ê¸°ì¤€ì…ë‹ˆë‹¤.
        </span>
      </p>

      <p><strong>Sample questions (selected):</strong></p>
      <ul>
        <li>êµ­ë¯¼ì—°ê¸ˆê³µë‹¨ì´ ë°œì£¼í•œ ì´ëŸ¬ë‹ì‹œìŠ¤í…œ ê´€ë ¨ ì‚¬ì—… ìš”êµ¬ì‚¬í•­ì„ ì •ë¦¬í•´ ì¤˜. / Summarize the e-learning project requirements by êµ­ë¯¼ì—°ê¸ˆê³µë‹¨.</li>
        <li>ê³µê³  ë²ˆí˜¸ê°€ 20240821893ì¸ ì‚¬ì—… ì´ë¦„ì´ ë­ì•¼? / What is the project title for announcement 20240821893?</li>
        <li>ì…ì°° ë§ˆê°ì¼ì´ 2024ë…„ 12ì›”ì¸ ì‚¬ì—…ì„ ì•Œë ¤ì¤˜. / List projects with bid close date in Dec 2024.</li>
        <li>í•œêµ­í•œì˜í•™ì—°êµ¬ì› í†µí•©ì •ë³´ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©ì—­ ì‚¬ì—…ì˜ ëª¨ë“  ìš”êµ¬ì‚¬í•­ ëª©ë¡ì„ ì•Œë ¤ì¤˜. / List all requirement identifications and names for the Korean Institute of Oriental Medicine project.</li>
      </ul>

      <p class="note">
        Key qualitative observation: OpenAI+MUP data-set produced the most useful and specific answers overall; OpenAI+Plumber often omitted official announcement numbers in summaries and produced overly short summaries. Full scoring table is available in the project report.
        <span class="dual">
          ì •ì„±ì  ê´€ì°°: OpenAI+MUP ì¡°í•©ì´ ê°€ì¥ êµ¬ì²´ì ì´ê³  ìœ ìš©í•œ ì‘ë‹µì„ ì œê³µí–ˆìœ¼ë©°, OpenAI+PlumberëŠ” ê³µê³ ë²ˆí˜¸ ëˆ„ë½ì´ë‚˜ ì§€ë‚˜ì¹˜ê²Œ ê°„ë‹¨í•œ ìš”ì•½ì„ ë³´ì´ëŠ” ê²½í–¥ì´ ìˆì—ˆìŠµë‹ˆë‹¤. ì „ì²´ í‰ì í‘œëŠ” ë³´ê³ ì„œì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
        </span>
      </p>

      <table class="metric-table" aria-label="qualitative scoring example">
        <thead>
          <tr><th>Data-Set</th><th>+2 (richer)</th><th>+1 (correct)</th><th>-1 (incorrect)</th></tr>
        </thead>
        <tbody>
          <tr><td>OpenAI + MUP (example)</td><td>â€”</td><td>â€”</td><td>â€”</td></tr>
          <tr><td>OpenAI + Plumber (example)</td><td>â€”</td><td>â€”</td><td>â€”</td></tr>
        </tbody>
      </table>

      <p class="note" style="text-align:center;">*Table above is a placeholder showing structure â€” see the project report for the complete scoring matrix.* <span class="dual">ìœ„ í‘œëŠ” í˜•ì‹ ì˜ˆì‹œì´ë©° ì „ì²´ í‰ì  í‘œëŠ” í”„ë¡œì íŠ¸ ë³´ê³ ì„œì— ìˆ˜ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤.</span></p>
    </section>
      </section>

      <section aria-labelledby="faiss">
        <h2 id="faiss">ğŸ”§ FAISS â€” Stacked Retriever Pipeline</h2>
        <p>
          Implemented a prototype stacked retriever (hybrid search â†’ multi-query â†’ re-rank â†’ contextual compression) and tested with Unstructured IO parsed docs and OpenAI embeddings. Components: MultiVectorRetriever, MultiQueryRetriever, BM25 hybrid, CrossEncoder re-ranker, LLM-based contextual compressor.
          <span class="dual">í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ â†’ ë‹¤ì¤‘ ì§ˆì˜ â†’ ì¬ì •ë ¬ â†’ ë¬¸ë§¥ ì••ì¶• íë¦„ì˜ í”„ë¡œí† íƒ€ì…ì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.</span>
        </p>

        <pre class="code"><code>def create_stacked_retriever(base_retriever):
    """Full pipeline: hybrid â†’ multi-query â†’ re-rank â†’ contextual compression."""
    return add_compression(
        add_reranking(
            add_multi_query(
                add_hybrid_search(base_retriever)
            )
        )
    )</code></pre>
      </section>

      <section aria-labelledby="next">
        <h2 id="next">ğŸ’¡ Reflection & Next steps</h2>
        <p>
          Lessons: parser choice affects downstream retrieval; embedding normalization shapes retriever design; and human-scored qualitative evaluation is critical. Next steps: expand automatic table-structure parsing and fine-tune reranker models.
          <span class="dual">íŒŒì„œ ì„ íƒ, ì„ë² ë”© ì •ê·œí™”, ì •ì„±í‰ê°€ì˜ ì¤‘ìš”ì„±ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ëŠ” í‘œ êµ¬ì¡° ìë™í™” ë° ì¬ì •ë ¬ê¸° íŠœë‹ì…ë‹ˆë‹¤.</span>
        </p>

        <p class="note">Full notebooks, t-SNE/histograms, and evaluation matrices available in the repository and project report.</p>
      </section>

      <a href="index.html" class="back-link">â† Back to Projects</a>
    </div>
  </main>

  <footer class="footer">
    Â© 2025 Aaron â€” Built with â¤ï¸ using GitHub Pages
  </footer>
</body>
</html>